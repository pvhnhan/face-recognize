"""
Training script cho h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t
S·ª≠ d·ª•ng YOLOv7 cho face detection v√† DeepFace cho face recognition
"""

import os
import sys
import logging
import time
import json
from pathlib import Path
from typing import Dict, List, Optional
import cv2
import numpy as np
import pandas as pd
from datetime import datetime

# Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import c√°c module
sys.path.append(str(Path(__file__).parent.parent))

from utils.data_processor import DataProcessor
from utils.face_utils import FaceProcessor
from utils.image_utils import ImageProcessor
from config.config import TRAINING_CONFIG, MODEL_CONFIG, DATA_CONFIG

# Thi·∫øt l·∫≠p logging
logging.basicConfig(
    level=getattr(logging, TRAINING_CONFIG['logging']['level']),
    format=TRAINING_CONFIG['logging']['format'],
    handlers=[
        logging.FileHandler(TRAINING_CONFIG['logging']['file']),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class FaceRecognitionTrainer:
    """
    L·ªõp hu·∫•n luy·ªán h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t
    """
    
    def __init__(self):
        """Kh·ªüi t·∫°o trainer"""
        self.data_processor = DataProcessor()
        self.face_processor = FaceProcessor()
        self.image_processor = ImageProcessor()
        
        # ƒê∆∞·ªùng d·∫´n
        self.data_dir = Path(DATA_CONFIG['data_dir'])
        self.models_dir = Path(MODEL_CONFIG['models_dir'])
        self.yolo_dataset_dir = self.data_dir / 'yolo_dataset'
        self.embeddings_dir = self.models_dir / 'face_embeddings'
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        self.embeddings_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("Kh·ªüi t·∫°o Face Recognition Trainer")
    
    def prepare_dataset(self) -> bool:
        """
        Chu·∫©n b·ªã dataset cho training
        
        Returns:
            bool: True n·∫øu th√†nh c√¥ng
        """
        try:
            logger.info("B·∫Øt ƒë·∫ßu chu·∫©n b·ªã dataset...")
            
            # Ki·ªÉm tra metadata
            metadata_path = self.data_dir / 'metadata.csv'
            if not metadata_path.exists():
                logger.error("Kh√¥ng t√¨m th·∫•y metadata.csv")
                return False
            
            # ƒê·ªçc metadata ƒë·ªÉ ki·ªÉm tra
            metadata_df = pd.read_csv(metadata_path)
            logger.info(f"ƒê·ªçc ƒë∆∞·ª£c {len(metadata_df)} records t·ª´ metadata")
            
            # Chu·∫©n b·ªã YOLO dataset (kh√¥ng c·∫ßn truy·ªÅn metadata_df)
            success = self.data_processor.prepare_yolo_dataset(
                output_dir=self.yolo_dataset_dir
            )
            
            if success:
                logger.info("Chu·∫©n b·ªã dataset th√†nh c√¥ng!")
                return True
            else:
                logger.error("Chu·∫©n b·ªã dataset th·∫•t b·∫°i!")
                return False
                
        except Exception as e:
            logger.error(f"L·ªói khi chu·∫©n b·ªã dataset: {e}")
            return False
    
    def create_embeddings(self) -> bool:
        """
        T·∫°o embeddings cho t·∫•t c·∫£ khu√¥n m·∫∑t trong dataset
        
        Returns:
            bool: True n·∫øu th√†nh c√¥ng
        """
        try:
            logger.info("B·∫Øt ƒë·∫ßu t·∫°o embeddings...")
            
            # ƒê·ªçc metadata
            metadata_path = self.data_dir / 'metadata.csv'
            metadata_df = pd.read_csv(metadata_path)
            
            # T·∫°o embeddings mapping
            embeddings_mapping = {}
            total_faces = 0
            successful_faces = 0
            
            for idx, row in metadata_df.iterrows():
                try:
                    image_path = self.data_dir / 'raw_images' / row['filename']
                    if not image_path.exists():
                        logger.warning(f"Kh√¥ng t√¨m th·∫•y ·∫£nh: {image_path}")
                        continue
                    
                    # ƒê·ªçc ·∫£nh
                    image = cv2.imread(str(image_path))
                    if image is None:
                        logger.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
                        continue
                    
                    # Ph√°t hi·ªán khu√¥n m·∫∑t
                    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                    faces = face_cascade.detectMultiScale(gray, 1.1, 4)
                    
                    if len(faces) == 0:
                        logger.warning(f"Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong: {image_path}")
                        continue
                    
                    # L·∫•y khu√¥n m·∫∑t ƒë·∫ßu ti√™n
                    x, y, w, h = faces[0]
                    face_region = image[y:y+h, x:x+w]
                    
                    # Tr√≠ch xu·∫•t embedding
                    face_embedding = self.face_processor.extract_face_embedding(face_region)
                    
                    if face_embedding is not None:
                        # L∆∞u embedding
                        embedding_key = f"{row['employee_id']}_{row['filename']}"
                        embeddings_mapping[embedding_key] = {
                            'employee_id': row['employee_id'],
                            'full_name': row['full_name'],
                            'image_path': str(image_path),
                            'embedding': face_embedding.tolist(),
                            'bbox': [x, y, w, h],
                            'created_at': datetime.now().isoformat()
                        }
                        successful_faces += 1
                        logger.info(f"T·∫°o embedding th√†nh c√¥ng cho: {row['full_name']} ({row['employee_id']})")
                    
                    total_faces += 1
                    
                except Exception as e:
                    logger.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh {row['filename']}: {e}")
                    continue
            
            # L∆∞u embeddings mapping
            embeddings_file = self.embeddings_dir / 'embeddings_mapping.json'
            with open(embeddings_file, 'w', encoding='utf-8') as f:
                json.dump(embeddings_mapping, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Ho√†n th√†nh t·∫°o embeddings: {successful_faces}/{total_faces} khu√¥n m·∫∑t th√†nh c√¥ng")
            logger.info(f"L∆∞u embeddings t·∫°i: {embeddings_file}")
            
            return successful_faces > 0
            
        except Exception as e:
            logger.error(f"L·ªói khi t·∫°o embeddings: {e}")
            return False
    
    def train_yolov7(self) -> bool:
        """
        Hu·∫•n luy·ªán YOLOv7 model cho face detection
        
        Returns:
            bool: True n·∫øu th√†nh c√¥ng
        """
        try:
            logger.info("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán YOLOv7...")
            
            # Ki·ªÉm tra YOLOv7 repository
            yolov7_path = Path(__file__).parent.parent / 'yolov7'
            if not yolov7_path.exists():
                logger.error("Kh√¥ng t√¨m th·∫•y YOLOv7 repository")
                return False
            
            # Ki·ªÉm tra dataset
            if not self.yolo_dataset_dir.exists():
                logger.error("Kh√¥ng t√¨m th·∫•y YOLO dataset")
                return False
            
            # T·∫°o file config cho YOLOv7
            data_yaml = self._create_yolo_data_config()
            if not data_yaml:
                return False
            
            # Chu·∫©n b·ªã l·ªánh training
            train_cmd = self._prepare_training_command(data_yaml)
            
            # Ch·∫°y training
            logger.info(f"Ch·∫°y l·ªánh training: {train_cmd}")
            
            import subprocess
            result = subprocess.run(
                train_cmd,
                shell=True,
                capture_output=True,
                text=True,
                cwd=yolov7_path
            )
            
            if result.returncode == 0:
                logger.info("Hu·∫•n luy·ªán YOLOv7 th√†nh c√¥ng!")
                return True
            else:
                logger.error("L·ªói trong qu√° tr√¨nh training:")
                logger.error(result.stderr)
                return False
                
        except Exception as e:
            logger.error(f"L·ªói khi hu·∫•n luy·ªán YOLOv7: {e}")
            return False
    
    def _create_yolo_data_config(self) -> Optional[Path]:
        """
        T·∫°o file config cho YOLOv7 training
        
        Returns:
            Path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file config
        """
        try:
            # ƒê·∫øm s·ªë l∆∞·ª£ng ·∫£nh trong t·ª´ng split
            train_dir = self.yolo_dataset_dir / 'images' / 'train'
            val_dir = self.yolo_dataset_dir / 'images' / 'val'
            
            train_count = len(list(train_dir.glob('*.jpg'))) + len(list(train_dir.glob('*.png')))
            val_count = len(list(val_dir.glob('*.jpg'))) + len(list(val_dir.glob('*.png')))
            
            # T·∫°o n·ªôi dung config
            config_content = f"""
# YOLOv7 Face Detection Dataset Config
path: {self.yolo_dataset_dir.absolute()}  # dataset root dir
train: images/train  # train images (relative to 'path')
val: images/val  # val images (relative to 'path')

# Classes
nc: 1  # number of classes
names: ['face']  # class names

# Dataset info
train_count: {train_count}
val_count: {val_count}
total_count: {train_count + val_count}
"""
            
            # L∆∞u config
            config_file = self.yolo_dataset_dir / 'dataset.yaml'
            with open(config_file, 'w') as f:
                f.write(config_content)
            
            logger.info(f"T·∫°o YOLO config t·∫°i: {config_file}")
            return config_file
            
        except Exception as e:
            logger.error(f"L·ªói khi t·∫°o YOLO config: {e}")
            return None
    
    def _prepare_training_command(self, data_yaml: Path) -> str:
        """
        Chu·∫©n b·ªã l·ªánh training YOLOv7
        
        Args:
            data_yaml: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file config
            
        Returns:
            str: L·ªánh training
        """
        # S·ª≠ d·ª•ng YOLOv7 tiny ƒë·ªÉ training nhanh h∆°n
        model_config = 'cfg/training/yolov7-tiny.yaml'
        
        cmd_parts = [
            "python train.py",
            f"--data {data_yaml}",
            f"--cfg {model_config}",
            f"--epochs {TRAINING_CONFIG['epochs']}",
            f"--batch-size {TRAINING_CONFIG['batch_size']}",
            f"--img-size {TRAINING_CONFIG['img_size']}",
            "--device 0" if TRAINING_CONFIG.get('use_gpu', False) else "--device cpu",
            "--project ../models/trained",
            "--name face_detection",
            "--exist-ok",
            "--save-period 10"
        ]
        
        return " ".join(cmd_parts)
    
    def save_training_log(self, training_info: Dict):
        """
        L∆∞u th√¥ng tin training
        
        Args:
            training_info: Th√¥ng tin training
        """
        try:
            log_file = Path(TRAINING_CONFIG['logging']['file']).parent / 'training_log.txt'
            
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write("=== FACE RECOGNITION TRAINING LOG ===\n")
                f.write(f"Training time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Dataset prepared: {training_info.get('dataset_prepared', False)}\n")
                f.write(f"Embeddings created: {training_info.get('embeddings_created', False)}\n")
                f.write(f"YOLOv7 trained: {training_info.get('yolov7_trained', False)}\n")
                f.write(f"Total faces processed: {training_info.get('total_faces', 0)}\n")
                f.write(f"Successful embeddings: {training_info.get('successful_embeddings', 0)}\n")
                f.write("=" * 40 + "\n")
            
            logger.info(f"L∆∞u training log t·∫°i: {log_file}")
            
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u training log: {e}")
    
    def run_training_pipeline(self) -> bool:
        """
        Ch·∫°y to√†n b·ªô pipeline training
        
        Returns:
            bool: True n·∫øu th√†nh c√¥ng
        """
        try:
            logger.info("B·∫Øt ƒë·∫ßu pipeline training...")
            start_time = time.time()
            
            training_info = {
                'dataset_prepared': False,
                'embeddings_created': False,
                'yolov7_trained': False,
                'total_faces': 0,
                'successful_embeddings': 0
            }
            
            # B∆∞·ªõc 1: Chu·∫©n b·ªã dataset
            logger.info("=== B∆Ø·ªöC 1: Chu·∫©n b·ªã dataset ===")
            if self.prepare_dataset():
                training_info['dataset_prepared'] = True
                logger.info("‚úÖ Chu·∫©n b·ªã dataset th√†nh c√¥ng")
            else:
                logger.error("‚ùå Chu·∫©n b·ªã dataset th·∫•t b·∫°i")
                return False
            
            # B∆∞·ªõc 2: T·∫°o embeddings
            logger.info("=== B∆Ø·ªöC 2: T·∫°o embeddings ===")
            if self.create_embeddings():
                training_info['embeddings_created'] = True
                logger.info("‚úÖ T·∫°o embeddings th√†nh c√¥ng")
            else:
                logger.error("‚ùå T·∫°o embeddings th·∫•t b·∫°i")
                return False
            
            # B∆∞·ªõc 3: Hu·∫•n luy·ªán YOLOv7
            logger.info("=== B∆Ø·ªöC 3: Hu·∫•n luy·ªán YOLOv7 ===")
            if self.train_yolov7():
                training_info['yolov7_trained'] = True
                logger.info("‚úÖ Hu·∫•n luy·ªán YOLOv7 th√†nh c√¥ng")
            else:
                logger.warning("‚ö†Ô∏è Hu·∫•n luy·ªán YOLOv7 th·∫•t b·∫°i (c√≥ th·ªÉ s·ª≠ d·ª•ng pretrained)")
            
            # L∆∞u training log
            training_time = time.time() - start_time
            training_info['training_time'] = training_time
            self.save_training_log(training_info)
            
            logger.info(f"Pipeline training ho√†n th√†nh trong {training_time:.2f} gi√¢y")
            return True
            
        except Exception as e:
            logger.error(f"L·ªói trong training pipeline: {e}")
            return False

def main():
    """H√†m main ƒë·ªÉ ch·∫°y training"""
    trainer = FaceRecognitionTrainer()
    
    # Ch·∫°y pipeline training
    success = trainer.run_training_pipeline()
    
    if success:
        logger.info("üéâ Training ho√†n th√†nh th√†nh c√¥ng!")
        print("Training ho√†n th√†nh th√†nh c√¥ng!")
    else:
        logger.error("‚ùå Training th·∫•t b·∫°i!")
        print("Training th·∫•t b·∫°i!")

if __name__ == '__main__':
    main() 