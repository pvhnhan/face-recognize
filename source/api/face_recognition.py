"""
API endpoints cho h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t
S·ª≠ d·ª•ng YOLOv7 ch√≠nh th·ª©c t·ª´ repository GitHub: https://github.com/WongKinYiu/yolov7

C√°c endpoints:
- /detect: Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng YOLOv7
- /recognize: Nh·∫≠n di·ªán khu√¥n m·∫∑t (detection + recognition)
- /batch: X·ª≠ l√Ω batch ·∫£nh
- /status: Tr·∫°ng th√°i h·ªá th·ªëng
"""

import os
import sys
import logging
import base64
import json
import time
import subprocess
from pathlib import Path
from typing import List, Dict, Optional
from flask import Blueprint, request, jsonify, current_app
from flask_restx import Resource, fields, Namespace
import cv2
import numpy as np
from datetime import datetime

# Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import c√°c module
sys.path.append(str(Path(__file__).parent.parent))

from utils.face_utils import FaceProcessor
from utils.image_utils import ImageProcessor
from config.config import FACE_RECOGNITION_CONFIG, MODEL_CONFIG, FLASK_CONFIG

# Thi·∫øt l·∫≠p logging
logger = logging.getLogger(__name__)

# T·∫°o Blueprint
face_recognition_bp = Blueprint('face_recognition', __name__, url_prefix='/api/face-recognition')

# T·∫°o namespace cho Swagger
ns = Namespace('face-recognition', description='Face recognition operations')

# ƒê·ªãnh nghƒ©a models cho Swagger
face_detection_model = ns.model('FaceDetection', {
    'faces': fields.List(fields.Raw, description='Danh s√°ch khu√¥n m·∫∑t ƒë∆∞·ª£c ph√°t hi·ªán'),
    'total_faces': fields.Integer(description='T·ªïng s·ªë khu√¥n m·∫∑t'),
    'status': fields.String(description='Tr·∫°ng th√°i x·ª≠ l√Ω')
})

face_recognition_model = ns.model('FaceRecognition', {
    'full_name': fields.String(description='T√™n ƒë·∫ßy ƒë·ªß c·ªßa ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán'),
    'employee_id': fields.String(description='ID nh√¢n vi√™n'),
    'input_image': fields.String(description='·∫¢nh input d·∫°ng base64'),
    'matched_images': fields.List(fields.String, description='Danh s√°ch ·∫£nh kh·ªõp'),
    'similarity_score': fields.Float(description='ƒê·ªô t∆∞∆°ng ƒë·ªìng (0-1)'),
    'status': fields.String(description='Tr·∫°ng th√°i x·ª≠ l√Ω')
})

batch_recognition_model = ns.model('BatchRecognition', {
    'results': fields.List(fields.Raw, description='K·∫øt qu·∫£ nh·∫≠n di·ªán cho t·ª´ng ·∫£nh'),
    'total_processed': fields.Integer(description='T·ªïng s·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω'),
    'status': fields.String(description='Tr·∫°ng th√°i x·ª≠ l√Ω')
})

error_model = ns.model('Error', {
    'error': fields.String(description='M√¥ t·∫£ l·ªói'),
    'status': fields.String(description='Tr·∫°ng th√°i l·ªói')
})

training_model = ns.model('Training', {
    'status': fields.String(description='Tr·∫°ng th√°i training'),
    'status_code': fields.String(description='M√£ tr·∫°ng th√°i'),
    'message': fields.String(description='Th√¥ng b√°o'),
    'start_time': fields.String(description='Th·ªùi gian b·∫Øt ƒë·∫ßu (ISO format)'),
    'end_time': fields.String(description='Th·ªùi gian k·∫øt th√∫c (ISO format)'),
    'estimated_duration': fields.String(description='Th·ªùi gian ∆∞·ªõc t√≠nh'),
    'steps': fields.List(fields.String, description='Danh s√°ch c√°c b∆∞·ªõc'),
    'progress': fields.Raw(description='Ti·∫øn ƒë·ªô hi·ªán t·∫°i'),
    'steps_completed': fields.Raw(description='C√°c b∆∞·ªõc ƒë√£ ho√†n th√†nh'),
    'statistics': fields.Raw(description='Th·ªëng k√™ training'),
    'overview': fields.Raw(description='T·ªïng quan training'),
    'elapsed_time': fields.Float(description='Th·ªùi gian ƒë√£ ch·∫°y (gi√¢y)'),
    'estimated_remaining': fields.Float(description='Th·ªùi gian c√≤n l·∫°i ∆∞·ªõc t√≠nh (gi√¢y)')
})

class FaceRecognitionAPI:
    """
    L·ªõp x·ª≠ l√Ω API nh·∫≠n di·ªán khu√¥n m·∫∑t
    S·ª≠ d·ª•ng YOLOv7 ch√≠nh th·ª©c cho face detection v√† DeepFace cho recognition
    """
    
    def __init__(self):
        """Kh·ªüi t·∫°o API"""
        self.face_processor = FaceProcessor()
        self.image_processor = ImageProcessor()
        
        # Ki·ªÉm tra YOLOv7 repository
        self.yolov7_path = Path(__file__).parent.parent / 'yolov7'
        self.yolov7_available = self._check_yolov7_availability()
        
        # Weights path
        self.weights_path = str(MODEL_CONFIG['trained_weights'])
        
        logger.info("Kh·ªüi t·∫°o Face Recognition API")
        logger.info(f"YOLOv7 available: {self.yolov7_available}")
    
    def _check_yolov7_availability(self) -> bool:
        """
        Ki·ªÉm tra YOLOv7 repository c√≥ s·∫µn kh√¥ng
        
        Returns:
            bool: True n·∫øu YOLOv7 c√≥ s·∫µn
        """
        if not self.yolov7_path.exists():
            logger.warning("YOLOv7 repository kh√¥ng t·ªìn t·∫°i")
            return False
        
        # Ki·ªÉm tra c√°c file c·∫ßn thi·∫øt
        required_files = [
            'detect.py',
            'models/experimental.py',
            'utils/general.py',
            'utils/augmentations.py'
        ]
        
        for file_path in required_files:
            if not (self.yolov7_path / file_path).exists():
                logger.warning(f"Thi·∫øu file YOLOv7: {file_path}")
                return False
        
        logger.info("YOLOv7 repository ƒë√£ s·∫µn s√†ng cho API")
        return True
    
    def detect_faces_yolov7(self, image_path: str) -> List[Dict]:
        """
        Ph√°t hi·ªán khu√¥n m·∫∑t s·ª≠ d·ª•ng YOLOv7 ch√≠nh th·ª©c
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
            
        Returns:
            List[Dict]: Danh s√°ch khu√¥n m·∫∑t ƒë∆∞·ª£c ph√°t hi·ªán
        """
        if not self.yolov7_available:
            logger.warning("YOLOv7 kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng OpenCV fallback")
            return self._detect_faces_opencv(image_path)
        
        logger.info(f"Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng YOLOv7: {image_path}")
        
        try:
            # T·∫°o l·ªánh inference theo YOLOv7 ch√≠nh th·ª©c
            inference_cmd = self._prepare_yolov7_inference_command(image_path)
            
            # Ch·∫°y inference trong th∆∞ m·ª•c YOLOv7
            result = subprocess.run(
                inference_cmd,
                shell=True,
                capture_output=True,
                text=True,
                cwd=self.yolov7_path
            )
            
            if result.returncode == 0:
                logger.info("YOLOv7 inference th√†nh c√¥ng!")
                # Parse k·∫øt qu·∫£ t·ª´ output
                detected_faces = self._parse_yolov7_output(result.stdout, image_path)
                return detected_faces
            else:
                logger.error("L·ªói trong YOLOv7 inference:")
                logger.error(result.stderr)
                return self._detect_faces_opencv(image_path)
                
        except Exception as e:
            logger.error(f"L·ªói khi ch·∫°y YOLOv7 inference: {e}")
            return self._detect_faces_opencv(image_path)
    
    def _prepare_yolov7_inference_command(self, image_path: str) -> str:
        """
        T·∫°o l·ªánh inference theo format YOLOv7 ch√≠nh th·ª©c
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
            
        Returns:
            str: L·ªánh inference
        """
        # Theo YOLOv7 ch√≠nh th·ª©c: https://github.com/WongKinYiu/yolov7
        cmd_parts = [
            "python detect.py",
            f"--weights {self.weights_path}",
            f"--source {image_path}",
            f"--conf {MODEL_CONFIG['confidence_threshold']}",
            f"--iou {MODEL_CONFIG['nms_threshold']}",
            f"--img-size {MODEL_CONFIG.get('img_size', 640)}",
            "--device 0" if torch.cuda.is_available() else "--device cpu",
            "--project ../outputs",
            "--name face_detection_results",
            "--exist-ok",
            "--save-txt"  # L∆∞u k·∫øt qu·∫£ d·∫°ng text
        ]
        
        return " ".join(cmd_parts)
    
    def _parse_yolov7_output(self, output: str, image_path: str) -> List[Dict]:
        """
        Parse k·∫øt qu·∫£ t·ª´ YOLOv7 output
        
        Args:
            output: Output t·ª´ YOLOv7
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh g·ªëc
            
        Returns:
            List[Dict]: Danh s√°ch khu√¥n m·∫∑t ƒë∆∞·ª£c ph√°t hi·ªán
        """
        detected_faces = []
        
        try:
            # ƒê·ªçc ·∫£nh ƒë·ªÉ l·∫•y k√≠ch th∆∞·ªõc
            image = cv2.imread(image_path)
            if image is None:
                return detected_faces
            
            h, w = image.shape[:2]
            
            # T√¨m file labels trong output
            output_dir = Path('outputs/face_detection_results/labels')
            image_name = Path(image_path).stem
            
            label_file = output_dir / f"{image_name}.txt"
            
            if label_file.exists():
                with open(label_file, 'r') as f:
                    lines = f.readlines()
                
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        # Format YOLO: class x_center y_center width height confidence
                        class_id = int(parts[0])
                        x_center = float(parts[1]) * w
                        y_center = float(parts[2]) * h
                        width = float(parts[3]) * w
                        height = float(parts[4]) * h
                        confidence = float(parts[5]) if len(parts) > 5 else 0.9
                        
                        # Chuy·ªÉn ƒë·ªïi sang format bbox
                        x1 = int(x_center - width / 2)
                        y1 = int(y_center - height / 2)
                        x2 = int(x_center + width / 2)
                        y2 = int(y_center + height / 2)
                        
                        face_info = {
                            'bbox': (x1, y1, x2 - x1, y2 - y1),
                            'confidence': confidence,
                            'face_region': image[y1:y2, x1:x2],
                            'class_id': class_id,
                            'class_name': 'face'
                        }
                        detected_faces.append(face_info)
            
            logger.info(f"YOLOv7 ph√°t hi·ªán {len(detected_faces)} khu√¥n m·∫∑t")
            
        except Exception as e:
            logger.error(f"L·ªói khi parse YOLOv7 output: {e}")
        
        return detected_faces
    
    def _detect_faces_opencv(self, image_path: str) -> List[Dict]:
        """
        Fallback face detection s·ª≠ d·ª•ng OpenCV
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
            
        Returns:
            List[Dict]: Danh s√°ch khu√¥n m·∫∑t ƒë∆∞·ª£c ph√°t hi·ªán
        """
        try:
            image = cv2.imread(image_path)
            if image is None:
                return []
            
            # S·ª≠ d·ª•ng OpenCV face detection
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            detected_faces = []
            for (x, y, w, h) in faces:
                face_info = {
                    'bbox': (x, y, w, h),
                    'confidence': 0.8,  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
                    'face_region': image[y:y+h, x:x+w],
                    'class_id': 0,
                    'class_name': 'face'
                }
                detected_faces.append(face_info)
            
            logger.info(f"OpenCV fallback ph√°t hi·ªán {len(detected_faces)} khu√¥n m·∫∑t")
            return detected_faces
            
        except Exception as e:
            logger.error(f"L·ªói trong OpenCV face detection: {e}")
            return []
    
    def recognize_faces(self, image_path: str) -> List[Dict]:
        """
        Nh·∫≠n di·ªán khu√¥n m·∫∑t trong ·∫£nh
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
            
        Returns:
            List[Dict]: K·∫øt qu·∫£ nh·∫≠n di·ªán cho t·ª´ng khu√¥n m·∫∑t
        """
        logger.info(f"B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t: {image_path}")
        
        # Ph√°t hi·ªán khu√¥n m·∫∑t
        detected_faces = self.detect_faces_yolov7(image_path)
        
        if not detected_faces:
            return []
        
        recognition_results = []
        
        for i, face_info in enumerate(detected_faces):
            try:
                # Tr√≠ch xu·∫•t embedding
                face_embedding = self.face_processor.extract_face_embedding(face_info['face_region'])
                
                # T√¨m khu√¥n m·∫∑t t∆∞∆°ng t·ª±
                employee_id, similarity, metadata = self.face_processor.find_most_similar_face(face_embedding)
                
                result = {
                    'face_index': i,
                    'bbox': face_info['bbox'],
                    'confidence': face_info['confidence'],
                    'employee_id': employee_id,
                    'full_name': metadata.get('full_name', 'Unknown') if metadata else 'Unknown',
                    'similarity': similarity,
                    'is_recognized': similarity >= FACE_RECOGNITION_CONFIG['similarity_threshold']
                }
                
                recognition_results.append(result)
                
            except Exception as e:
                logger.error(f"L·ªói khi nh·∫≠n di·ªán face {i}: {e}")
                result = {
                    'face_index': i,
                    'bbox': face_info['bbox'],
                    'confidence': face_info['confidence'],
                    'employee_id': 'Unknown',
                    'full_name': 'Unknown',
                    'similarity': 0.0,
                    'is_recognized': False,
                    'error': str(e)
                }
                recognition_results.append(result)
        
        return recognition_results

# Kh·ªüi t·∫°o API instance
api_instance = FaceRecognitionAPI()

# Flask-RESTX Resource Classes cho Swagger
@ns.route('/detect')
class FaceDetectionAPI(Resource):
    @ns.doc('detect_faces')
    @ns.response(200, 'Success', face_detection_model)
    @ns.response(400, 'Bad Request', error_model)
    @ns.response(500, 'Internal Server Error', error_model)
    def post(self):
        """
        Ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh
        
        G·ª≠i ·∫£nh d∆∞·ªõi d·∫°ng file upload ho·∫∑c base64 string
        """
        try:
            start_time = time.time()
            
            # Ki·ªÉm tra request
            if 'image' not in request.files and 'image_base64' not in request.form:
                return {
                    'error': 'Thi·∫øu ·∫£nh input',
                    'message': 'G·ª≠i file ·∫£nh ho·∫∑c base64 string',
                    'status': 'error'
                }, 400
            
            # X·ª≠ l√Ω ·∫£nh input
            image_path = None
            if 'image' in request.files:
                # Upload file
                file = request.files['image']
                if file.filename == '':
                    return {'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn', 'status': 'error'}, 400
                
                # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
                allowed_extensions = FLASK_CONFIG['allowed_extensions']
                if not any(file.filename.lower().endswith(ext) for ext in allowed_extensions):
                    return {
                        'error': 'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£',
                        'allowed_formats': allowed_extensions,
                        'status': 'error'
                    }, 400
                
                # L∆∞u file t·∫°m
                temp_dir = FLASK_CONFIG['temp_dir']
                temp_dir.mkdir(parents=True, exist_ok=True)
                
                image_path = temp_dir / f"temp_{int(time.time())}_{file.filename}"
                file.save(str(image_path))
                
            elif 'image_base64' in request.form:
                # Base64 string
                image_base64 = request.form['image_base64']
                try:
                    # L∆∞u base64 th√†nh file t·∫°m
                    temp_dir = FLASK_CONFIG['temp_dir']
                    temp_dir.mkdir(parents=True, exist_ok=True)
                    
                    image_path = temp_dir / f"temp_{int(time.time())}.jpg"
                    image = api_instance.image_processor.base64_to_image(image_base64)
                    cv2.imwrite(str(image_path), image)
                    
                except Exception as e:
                    return {'error': f'L·ªói khi decode base64: {str(e)}', 'status': 'error'}, 400
            
            if image_path is None:
                return {'error': 'Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh input', 'status': 'error'}, 400
            
            try:
                # Ph√°t hi·ªán khu√¥n m·∫∑t
                detected_faces = api_instance.detect_faces_yolov7(str(image_path))
                
                # ƒê·ªçc ·∫£nh ƒë·ªÉ v·∫Ω k·∫øt qu·∫£
                image = cv2.imread(str(image_path))
                if image is not None:
                    # V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh
                    result_image = api_instance.image_processor.draw_detection_results(image, detected_faces)
                    
                    # Chuy·ªÉn ƒë·ªïi ·∫£nh sang base64
                    result_image_base64 = api_instance.image_processor.image_to_base64(result_image)
                else:
                    result_image_base64 = ""
                
                # Chu·∫©n b·ªã response
                processing_time = time.time() - start_time
                
                return {
                    'faces': detected_faces,
                    'total_faces': len(detected_faces),
                    'result_image_base64': result_image_base64,
                    'processing_time': processing_time,
                    'status': 'success'
                }
                
            finally:
                # X√≥a file t·∫°m
                if image_path and image_path.exists():
                    try:
                        image_path.unlink()
                    except:
                        pass
        
        except Exception as e:
            logger.error(f"L·ªói trong API detect_faces: {e}")
            return {
                'error': 'L·ªói server',
                'message': str(e),
                'status': 'error'
            }, 500

@ns.route('/recognize')
class FaceRecognitionAPI(Resource):
    @ns.doc('recognize_faces')
    @ns.response(200, 'Success', face_recognition_model)
    @ns.response(400, 'Bad Request', error_model)
    @ns.response(500, 'Internal Server Error', error_model)
    def post(self):
        """
        Nh·∫≠n di·ªán khu√¥n m·∫∑t trong ·∫£nh
        
        G·ª≠i ·∫£nh d∆∞·ªõi d·∫°ng file upload ho·∫∑c base64 string
        """
        try:
            start_time = time.time()
            
            # Ki·ªÉm tra request
            if 'image' not in request.files and 'image_base64' not in request.form:
                return {
                    'error': 'Thi·∫øu ·∫£nh input',
                    'message': 'G·ª≠i file ·∫£nh ho·∫∑c base64 string',
                    'status': 'error'
                }, 400
            
            # X·ª≠ l√Ω ·∫£nh input (t∆∞∆°ng t·ª± nh∆∞ detect)
            image_path = None
            if 'image' in request.files:
                file = request.files['image']
                if file.filename == '':
                    return {'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn', 'status': 'error'}, 400
                
                temp_dir = FLASK_CONFIG['temp_dir']
                temp_dir.mkdir(parents=True, exist_ok=True)
                image_path = temp_dir / f"temp_{int(time.time())}_{file.filename}"
                file.save(str(image_path))
                
            elif 'image_base64' in request.form:
                image_base64 = request.form['image_base64']
                try:
                    temp_dir = FLASK_CONFIG['temp_dir']
                    temp_dir.mkdir(parents=True, exist_ok=True)
                    image_path = temp_dir / f"temp_{int(time.time())}.jpg"
                    image = api_instance.image_processor.base64_to_image(image_base64)
                    cv2.imwrite(str(image_path), image)
                except Exception as e:
                    return {'error': f'L·ªói khi decode base64: {str(e)}', 'status': 'error'}, 400
            
            if image_path is None:
                return {'error': 'Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh input', 'status': 'error'}, 400
            
            try:
                # Nh·∫≠n di·ªán khu√¥n m·∫∑t
                recognition_results = api_instance.recognize_faces(str(image_path))
                
                if not recognition_results:
                    return {
                        'full_name': 'Unknown',
                        'employee_id': None,
                        'input_image': api_instance.image_processor.image_to_base64(cv2.imread(str(image_path))),
                        'matched_images': [],
                        'similarity_score': 0.0,
                        'status': 'no_face_detected'
                    }
                
                # L·∫•y k·∫øt qu·∫£ ƒë·∫ßu ti√™n
                result = recognition_results[0]
                
                processing_time = time.time() - start_time
                
                return {
                    'full_name': result['full_name'],
                    'employee_id': result['employee_id'],
                    'input_image': api_instance.image_processor.image_to_base64(cv2.imread(str(image_path))),
                    'matched_images': [result.get('matched_image', '')],
                    'similarity_score': result['similarity'],
                    'status': 'success'
                }
                
            finally:
                # X√≥a file t·∫°m
                if image_path and image_path.exists():
                    try:
                        image_path.unlink()
                    except:
                        pass
        
        except Exception as e:
            logger.error(f"L·ªói trong API recognize_faces: {e}")
            return {
                'error': 'L·ªói server',
                'message': str(e),
                'status': 'error'
            }, 500

@ns.route('/batch')
class BatchRecognitionAPI(Resource):
    @ns.doc('batch_recognition')
    @ns.response(200, 'Success', batch_recognition_model)
    @ns.response(400, 'Bad Request', error_model)
    @ns.response(500, 'Internal Server Error', error_model)
    def post(self):
        """
        Nh·∫≠n di·ªán khu√¥n m·∫∑t cho nhi·ªÅu ·∫£nh
        
        G·ª≠i danh s√°ch ·∫£nh d∆∞·ªõi d·∫°ng base64 strings
        """
        try:
            start_time = time.time()
            
            # Ki·ªÉm tra request
            if 'images' not in request.json:
                return {
                    'error': 'Thi·∫øu danh s√°ch ·∫£nh',
                    'message': 'G·ª≠i danh s√°ch ·∫£nh d∆∞·ªõi d·∫°ng base64',
                    'status': 'error'
                }, 400
            
            images_base64 = request.json['images']
            if not isinstance(images_base64, list):
                return {
                    'error': 'Images ph·∫£i l√† danh s√°ch',
                    'status': 'error'
                }, 400
            
            results = []
            for i, image_base64 in enumerate(images_base64):
                try:
                    # Decode base64
                    image = api_instance.image_processor.base64_to_image(image_base64)
                    
                    # L∆∞u t·∫°m ƒë·ªÉ x·ª≠ l√Ω
                    temp_dir = FLASK_CONFIG['temp_dir']
                    temp_dir.mkdir(parents=True, exist_ok=True)
                    temp_path = temp_dir / f"temp_batch_{i}_{int(time.time())}.jpg"
                    cv2.imwrite(str(temp_path), image)
                    
                    # Nh·∫≠n di·ªán
                    recognition_results = api_instance.recognize_faces(str(temp_path))
                    
                    if recognition_results:
                        result = recognition_results[0]
                        results.append({
                            'image_index': i,
                            'full_name': result['full_name'],
                            'employee_id': result['employee_id'],
                            'similarity_score': result['similarity'],
                            'status': 'success'
                        })
                    else:
                        results.append({
                            'image_index': i,
                            'full_name': 'Unknown',
                            'employee_id': None,
                            'similarity_score': 0.0,
                            'status': 'no_face_detected'
                        })
                    
                    # X√≥a file t·∫°m
                    if temp_path.exists():
                        temp_path.unlink()
                    
                except Exception as e:
                    logger.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh {i}: {e}")
                    results.append({
                        'image_index': i,
                        'full_name': 'Unknown',
                        'employee_id': None,
                        'similarity_score': 0.0,
                        'status': 'error',
                        'error': str(e)
                    })
            
            processing_time = time.time() - start_time
            
            return {
                'results': results,
                'total_processed': len(images_base64),
                'processing_time': processing_time,
                'status': 'success'
            }
        
        except Exception as e:
            logger.error(f"L·ªói trong API batch_recognition: {e}")
            return {
                'error': 'L·ªói server',
                'message': str(e),
                'status': 'error'
            }, 500

@ns.route('/status')
class StatusAPI(Resource):
    @ns.doc('get_status')
    @ns.response(200, 'Success')
    def get(self):
        """
        L·∫•y tr·∫°ng th√°i h·ªá th·ªëng
        """
        try:
            # L·∫•y th·ªëng k√™ embeddings
            embeddings_stats = api_instance.face_processor.get_embedding_statistics()
            
            return {
                'status': 'running',
                'embeddings': embeddings_stats,
                'message': 'H·ªá th·ªëng ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng'
            }
        
        except Exception as e:
            logger.error(f"L·ªói khi l·∫•y status: {e}")
            return {
                'status': 'error',
                'error': str(e)
            }, 500

# Training status tracking
train_status = {
    'running': False, 
    'success': None, 
    'log': '', 
    'start_time': None,
    'end_time': None,
    'start_timestamp': None,
    'end_timestamp': None,
    'status_code': None,
    'steps_completed': {
        'dataset_prepared': False,
        'embeddings_created': False,
        'yolov7_trained': False
    },
    'progress': {
        'current_step': '',
        'total_steps': 3,
        'completed_steps': 0
    },
    'statistics': {
        'total_faces': 0,
        'successful_embeddings': 0,
        'training_time': 0
    }
}

@ns.route('/train')
class FaceTrainAPI(Resource):
    @ns.doc('start_training')
    @ns.response(200, 'Training started', training_model)
    @ns.response(409, 'Training already running', training_model)
    @ns.response(500, 'Internal Server Error', error_model)
    def post(self):
        """
        B·∫Øt ƒë·∫ßu qu√° tr√¨nh training model
        """
        try:
            if train_status['running']:
                return {
                    'status': 'training', 
                    'status_code': 'running',
                    'message': 'Training is already running.',
                    'start_time': train_status['start_time'],
                    'progress': train_status['progress'],
                    'steps_completed': train_status['steps_completed'],
                    'overview': {
                        'is_running': True,
                        'is_completed': False,
                        'is_failed': False,
                        'total_steps': train_status['progress']['total_steps'],
                        'completed_steps': train_status['progress']['completed_steps'],
                        'completion_percentage': round((train_status['progress']['completed_steps'] / train_status['progress']['total_steps']) * 100, 1)
                    }
                }, 409
            
            def train_job():
                """Background training job"""
                try:
                    train_status['running'] = True
                    train_status['start_timestamp'] = time.time()
                    train_status['start_time'] = datetime.now().isoformat()
                    train_status['end_time'] = None
                    train_status['end_timestamp'] = None
                    train_status['status_code'] = 'running'
                    train_status['log'] = 'B·∫Øt ƒë·∫ßu training...'
                    train_status['progress']['current_step'] = 'Kh·ªüi t·∫°o'
                    train_status['progress']['completed_steps'] = 0
                    
                    # Import v√† kh·ªüi t·∫°o trainer
                    from core.train import FaceRecognitionTrainer
                    
                    # Kh·ªüi t·∫°o trainer
                    trainer = FaceRecognitionTrainer()
                    train_status['log'] = 'ƒê√£ kh·ªüi t·∫°o trainer, b·∫Øt ƒë·∫ßu pipeline...'
                    
                    # B∆∞·ªõc 1: Chu·∫©n b·ªã dataset
                    train_status['progress']['current_step'] = 'Chu·∫©n b·ªã dataset'
                    train_status['log'] = 'ƒêang chu·∫©n b·ªã dataset...'
                    
                    if trainer.prepare_dataset():
                        train_status['steps_completed']['dataset_prepared'] = True
                        train_status['progress']['completed_steps'] = 1
                        train_status['log'] = '‚úÖ Chu·∫©n b·ªã dataset th√†nh c√¥ng'
                    else:
                        train_status['log'] = '‚ùå Chu·∫©n b·ªã dataset th·∫•t b·∫°i'
                        train_status['status_code'] = 'failed'
                        train_status['success'] = False
                        return
                    
                    # B∆∞·ªõc 2: T·∫°o embeddings
                    train_status['progress']['current_step'] = 'T·∫°o embeddings'
                    train_status['log'] = 'ƒêang t·∫°o embeddings...'
                    
                    if trainer.create_embeddings():
                        train_status['steps_completed']['embeddings_created'] = True
                        train_status['progress']['completed_steps'] = 2
                        train_status['log'] = '‚úÖ T·∫°o embeddings th√†nh c√¥ng'
                    else:
                        train_status['log'] = '‚ùå T·∫°o embeddings th·∫•t b·∫°i'
                        train_status['status_code'] = 'failed'
                        train_status['success'] = False
                        return
                    
                    # B∆∞·ªõc 3: Hu·∫•n luy·ªán YOLOv7
                    train_status['progress']['current_step'] = 'Hu·∫•n luy·ªán YOLOv7'
                    train_status['log'] = 'ƒêang hu·∫•n luy·ªán YOLOv7...'
                    
                    if trainer.train_yolov7():
                        train_status['steps_completed']['yolov7_trained'] = True
                        train_status['progress']['completed_steps'] = 3
                        train_status['log'] = '‚úÖ Hu·∫•n luy·ªán YOLOv7 th√†nh c√¥ng'
                    else:
                        train_status['log'] = '‚ö†Ô∏è Hu·∫•n luy·ªán YOLOv7 th·∫•t b·∫°i (c√≥ th·ªÉ s·ª≠ d·ª•ng pretrained)'
                    
                    # Ho√†n th√†nh
                    train_status['end_timestamp'] = time.time()
                    train_status['end_time'] = datetime.now().isoformat()
                    train_status['statistics']['training_time'] = train_status['end_timestamp'] - train_status['start_timestamp']
                    train_status['success'] = True
                    train_status['status_code'] = 'completed'
                    train_status['log'] = 'üéâ Training ho√†n th√†nh th√†nh c√¥ng!'
                    
                except Exception as e:
                    train_status['end_timestamp'] = time.time()
                    train_status['end_time'] = datetime.now().isoformat()
                    train_status['success'] = False
                    train_status['status_code'] = 'error'
                    train_status['log'] = f'‚ùå L·ªói training: {str(e)}'
                    logger.error(f"L·ªói trong training job: {e}")
                finally:
                    train_status['running'] = False
            
            # Ch·∫°y training trong thread ri√™ng
            from threading import Thread
            Thread(target=train_job, daemon=True).start()
            
            return {
                'status': 'started',
                'status_code': 'started',
                'message': 'Training ƒë√£ ƒë∆∞·ª£c b·∫Øt ƒë·∫ßu',
                'start_time': train_status['start_time'],
                'estimated_duration': '5-10 ph√∫t',
                'steps': [
                    'Chu·∫©n b·ªã dataset',
                    'T·∫°o embeddings', 
                    'Hu·∫•n luy·ªán YOLOv7'
                ],
                'progress': train_status['progress'],
                'steps_completed': train_status['steps_completed']
            }
            
        except Exception as e:
            logger.error(f"L·ªói khi b·∫Øt ƒë·∫ßu training: {e}")
            return {
                'error': 'L·ªói server',
                'message': str(e),
                'status': 'error'
            }, 500

@ns.route('/train/status')
class FaceTrainStatusAPI(Resource):
    @ns.doc('get_training_status')
    @ns.response(200, 'Training status', training_model)
    @ns.response(500, 'Internal Server Error', error_model)
    def get(self):
        """
        L·∫•y tr·∫°ng th√°i training
        """
        try:
            status_info = train_status.copy()
            
            # T√≠nh th·ªùi gian ƒë√£ ch·∫°y
            if status_info['running'] and status_info['start_timestamp']:
                elapsed_time = time.time() - status_info['start_timestamp']
                status_info['elapsed_time'] = elapsed_time
                status_info['estimated_remaining'] = max(0, (300 - elapsed_time))  # ∆Ø·ªõc t√≠nh 5 ph√∫t
            else:
                status_info['elapsed_time'] = 0
                status_info['estimated_remaining'] = 0
            
            # Th√™m th√¥ng tin t·ªïng quan
            status_info['overview'] = {
                'is_running': status_info['running'],
                'is_completed': status_info['status_code'] == 'completed',
                'is_failed': status_info['status_code'] in ['failed', 'error'],
                'total_steps': status_info['progress']['total_steps'],
                'completed_steps': status_info['progress']['completed_steps'],
                'completion_percentage': round((status_info['progress']['completed_steps'] / status_info['progress']['total_steps']) * 100, 1)
            }
            
            return status_info
            
        except Exception as e:
            logger.error(f"L·ªói khi l·∫•y training status: {e}")
            return {
                'status': 'error',
                'error': str(e)
            }, 500 